# ROS2 Integration

**Connect Igris Runtime to robotics systems via ROS2 for AI-powered robot intelligence.**

Igris Runtime integrates seamlessly with ROS2 (Robot Operating System 2), enabling:
- **Natural language robot control** - Send commands in plain English
- **Sensor data processing** - AI analysis of camera, lidar, and sensor feeds
- **Real-time decision making** - Low-latency inference for autonomous systems
- **Multi-robot coordination** - Fleet-wide AI coordination via DDS

---

## Quick Start

### Prerequisites

**ROS2 Installation** (Humble Hawksbill or later):
```bash
# Ubuntu 22.04
sudo apt install ros-humble-desktop

# macOS (via Homebrew)
brew install ros

# Verify installation
source /opt/ros/humble/setup.bash  # Linux
ros2 --version  # Should show: ros2 doctor 0.10.4
```

**r2r bridge** (for Rust ↔ ROS2 communication):
```bash
# Install r2r from GitHub
git clone https://github.com/sequenceplanner/r2r
cd r2r
cargo build --release

# Or use pre-built binary (if available)
cargo install r2r
```

### 1. Enable ROS2 in Runtime

```json5
// config.json5
{
  "ros2": {
    "enabled": true,
    "domain_id": 0,                    // ROS2 DDS domain
    "namespace": "igris",              // Node namespace
    "node_name": "ai_inference_node",  // Node name
    "qos_profile": "default"           // QoS settings
  }
}
```

### 2. Start Runtime with ROS2

```bash
# Source ROS2 environment
source /opt/ros/humble/setup.bash

# Start runtime
./igris-runtime --config config.json5

# Verify ROS2 node is running
ros2 node list
# Should show: /igris/ai_inference_node
```

### 3. Send AI Request via ROS2

```bash
# Publish inference request
ros2 topic pub /igris/inference/request std_msgs/String \
  "data: 'What objects do you see in this image?'"

# Subscribe to response
ros2 topic echo /igris/inference/response
```

---

## Architecture

### ROS2 Node Structure

```
┌────────────────────────────────────────────┐
│  Igris Runtime                             │
│                                            │
│  ┌──────────────────────────────────────┐ │
│  │ ROS2 Node: /igris/ai_inference_node  │ │
│  │                                       │ │
│  │  Publishers:                         │ │
│  │  • /igris/inference/response         │ │
│  │  • /igris/status                     │ │
│  │  • /igris/metrics                    │ │
│  │                                       │ │
│  │  Subscribers:                        │ │
│  │  • /igris/inference/request          │ │
│  │  • /igris/config/update              │ │
│  │  • /robot/camera/image               │ │
│  │  • /robot/lidar/scan                 │ │
│  │                                       │ │
│  │  Services:                           │ │
│  │  • /igris/infer (sync inference)     │ │
│  │  • /igris/health (health check)      │ │
│  │  • /igris/reload_model               │ │
│  └──────────────────────────────────────┘ │
│                                            │
│  ┌──────────────────────────────────────┐ │
│  │ LocalLLMProvider (llama.cpp)         │ │
│  │  - Phi-3 Mini 4K                     │ │
│  │  - GPU offload (Metal/CUDA)          │ │
│  │  - Streaming responses               │ │
│  └──────────────────────────────────────┘ │
└────────────────────────────────────────────┘
                    │
                    │ DDS (ROS2 Middleware)
                    │
┌────────────────────────────────────────────┐
│  Robot System (ROS2)                       │
│  • Navigation stack                        │
│  • Perception pipeline                     │
│  • Motion planning                         │
│  • Sensor drivers                          │
└────────────────────────────────────────────┘
```

### Communication Patterns

**1. Async Topic-based** (for streaming data):
```
Robot Camera → /robot/camera/image → Igris Runtime
Igris Runtime → /igris/inference/response → Robot Controller
```

**2. Sync Service-based** (for request/reply):
```
Robot → /igris/infer (ROS2 Service) → Igris Runtime
       ← Response ←
```

---

## Configuration

### Full ROS2 Config

```json5
{
  "ros2": {
    // Basic settings
    "enabled": true,
    "domain_id": 0,              // 0-232, must match robot's domain
    "namespace": "igris",        // Namespace for all topics/services
    "node_name": "ai_inference_node",

    // QoS (Quality of Service)
    "qos_profile": "default",    // Options: default, sensor_data, parameter, services
    "history": "keep_last",      // keep_last or keep_all
    "depth": 10,                 // Queue depth for keep_last
    "reliability": "reliable",   // reliable or best_effort
    "durability": "volatile",    // volatile or transient_local

    // Topics
    "topics": {
      "inference_request": "/igris/inference/request",
      "inference_response": "/igris/inference/response",
      "status": "/igris/status",
      "metrics": "/igris/metrics"
    },

    // Services
    "services": {
      "infer": "/igris/infer",
      "health": "/igris/health",
      "reload_model": "/igris/reload_model"
    },

    // Subscriptions (sensor inputs)
    "subscriptions": [
      {
        "topic": "/robot/camera/image",
        "msg_type": "sensor_msgs/Image",
        "callback": "process_image"
      },
      {
        "topic": "/robot/lidar/scan",
        "msg_type": "sensor_msgs/LaserScan",
        "callback": "process_lidar"
      }
    ],

    // Performance
    "executor_threads": 4,       // Threads for ROS2 executor
    "spin_timeout_ms": 100,      // Executor spin timeout

    // Debugging
    "enable_ros_logging": true,  // Send logs to ROS2 logger
    "log_level": "info"          // debug, info, warn, error
  }
}
```

### Environment Variables

```bash
# ROS2 Domain (must match robot)
export ROS_DOMAIN_ID=0

# DDS middleware (optional)
export RMW_IMPLEMENTATION=rmw_fastrtps_cpp  # or rmw_cyclonedds_cpp

# Discovery timeout
export ROS_DISCOVERY_TIMEOUT=30
```

---

## Topics & Messages

### Inference Request Topic

**Topic:** `/igris/inference/request`
**Message Type:** `std_msgs/String` (MVP) or custom `igris_msgs/InferenceRequest`

**Example (simple):**
```bash
ros2 topic pub /igris/inference/request std_msgs/String \
  "data: 'Navigate to the kitchen'"
```

**Example (custom message):**
```bash
ros2 topic pub /igris/inference/request igris_msgs/InferenceRequest \
  "{prompt: 'Navigate to the kitchen', model: 'phi-3-mini-4k', max_tokens: 150}"
```

### Inference Response Topic

**Topic:** `/igris/inference/response`
**Message Type:** `std_msgs/String` (MVP) or custom `igris_msgs/InferenceResponse`

**Example response:**
```yaml
data: "I'll help you navigate to the kitchen. Based on the current map, I suggest taking the hallway to your left, then the second door on the right."
```

### Status Topic

**Topic:** `/igris/status`
**Message Type:** `igris_msgs/RuntimeStatus`

**Published every 5 seconds:**
```yaml
node_name: "ai_inference_node"
status: "healthy"  # healthy, degraded, error
uptime_secs: 3600
active_requests: 2
total_requests: 1520
error_count: 3
model_loaded: true
model_name: "phi-3-mini-4k-instruct"
gpu_enabled: true
```

### Metrics Topic

**Topic:** `/igris/metrics`
**Message Type:** `igris_msgs/InferenceMetrics`

**Published every 10 seconds:**
```yaml
avg_latency_ms: 245.5
p95_latency_ms: 380.2
p99_latency_ms: 520.8
requests_per_sec: 15.2
success_rate: 0.985
tokens_per_sec: 45.8
```

---

## Services

### Synchronous Inference Service

**Service:** `/igris/infer`
**Type:** `igris_msgs/Infer`

**Request:**
```yaml
prompt: "What objects are in front of the robot?"
model: "phi-3-mini-4k"  # Optional
max_tokens: 150         # Optional
temperature: 0.7        # Optional
```

**Response:**
```yaml
success: true
response: "I can see a chair, a table, and a potted plant."
latency_ms: 245
tokens_used: 32
model_used: "phi-3-mini-4k-instruct"
```

**Example call:**
```bash
ros2 service call /igris/infer igris_msgs/Infer \
  "{prompt: 'What do you see?', max_tokens: 100}"
```

### Health Check Service

**Service:** `/igris/health`
**Type:** `std_srvs/Trigger`

**Response:**
```yaml
success: true
message: "Runtime healthy. Model loaded: phi-3-mini-4k-instruct"
```

### Reload Model Service

**Service:** `/igris/reload_model`
**Type:** `igris_msgs/ReloadModel`

**Request:**
```yaml
model_path: "/models/phi-3-mini-128k-instruct-q4.gguf"
```

**Response:**
```yaml
success: true
message: "Model reloaded successfully"
previous_model: "phi-3-mini-4k-instruct"
new_model: "phi-3-mini-128k-instruct"
```

---

## Integration Examples

### Example 1: Voice-Controlled Robot

**Scenario:** User says "Go to the kitchen"

```python
#!/usr/bin/env python3
import rclpy
from rclpy.node import Node
from std_msgs.msg import String
from geometry_msgs.msg import PoseStamped

class VoiceControlNode(Node):
    def __init__(self):
        super().__init__('voice_control')

        # Subscribe to speech recognition
        self.voice_sub = self.create_subscription(
            String, '/speech/recognized', self.voice_callback, 10)

        # Publish to Igris inference
        self.inference_pub = self.create_publisher(
            String, '/igris/inference/request', 10)

        # Subscribe to Igris response
        self.response_sub = self.create_subscription(
            String, '/igris/inference/response', self.ai_callback, 10)

        # Publish navigation goals
        self.nav_pub = self.create_publisher(
            PoseStamped, '/goal_pose', 10)

    def voice_callback(self, msg):
        # Forward speech to AI
        self.get_logger().info(f'Voice command: {msg.data}')
        self.inference_pub.publish(msg)

    def ai_callback(self, msg):
        # Parse AI response and extract navigation goal
        self.get_logger().info(f'AI response: {msg.data}')

        # Example: Extract coordinates from response
        # "Navigate to kitchen at coordinates (5.2, 3.1)"
        # Then publish to /goal_pose

        goal = PoseStamped()
        goal.header.frame_id = 'map'
        goal.pose.position.x = 5.2
        goal.pose.position.y = 3.1
        self.nav_pub.publish(goal)

def main():
    rclpy.init()
    node = VoiceControlNode()
    rclpy.spin(node)
    rclpy.shutdown()

if __name__ == '__main__':
    main()
```

### Example 2: Vision-Based Object Detection

**Scenario:** Robot analyzes camera feed for objects

```python
#!/usr/bin/env python3
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from std_msgs.msg import String
from cv_bridge import CvBridge
import base64

class VisionAnalysisNode(Node):
    def __init__(self):
        super().__init__('vision_analysis')

        self.bridge = CvBridge()

        # Subscribe to camera
        self.image_sub = self.create_subscription(
            Image, '/robot/camera/image', self.image_callback, 10)

        # Publish to Igris (with image data)
        self.inference_pub = self.create_publisher(
            String, '/igris/inference/request', 10)

        # Subscribe to AI response
        self.response_sub = self.create_subscription(
            String, '/igris/inference/response', self.detection_callback, 10)

    def image_callback(self, msg):
        # Convert ROS Image to OpenCV format
        cv_image = self.bridge.imgmsg_to_cv2(msg, 'bgr8')

        # Encode to base64 for AI processing
        _, buffer = cv2.imencode('.jpg', cv_image)
        img_b64 = base64.b64encode(buffer).decode('utf-8')

        # Send to AI with multimodal prompt
        prompt = {
            'text': 'What objects are visible in this image? List them with positions.',
            'image': img_b64
        }

        self.inference_pub.publish(String(data=str(prompt)))

    def detection_callback(self, msg):
        # Parse AI response
        self.get_logger().info(f'Detected objects: {msg.data}')
        # Example output: "chair (left), table (center), plant (right)"

def main():
    rclpy.init()
    node = VisionAnalysisNode()
    rclpy.spin(node)
    rclpy.shutdown()

if __name__ == '__main__':
    main()
```

### Example 3: Fleet Coordination

**Scenario:** Multiple robots coordinate via centralized AI

```python
#!/usr/bin/env python3
import rclpy
from rclpy.node import Node
from std_msgs.msg import String

class FleetCoordinatorNode(Node):
    def __init__(self):
        super().__init__('fleet_coordinator')

        # Each robot publishes its status
        self.robot1_sub = self.create_subscription(
            String, '/robot1/status', lambda msg: self.robot_status('robot1', msg), 10)
        self.robot2_sub = self.create_subscription(
            String, '/robot2/status', lambda msg: self.robot_status('robot2', msg), 10)

        # AI coordination service
        self.ai_pub = self.create_publisher(
            String, '/igris/inference/request', 10)

        self.robot_states = {}

    def robot_status(self, robot_id, msg):
        self.robot_states[robot_id] = msg.data

        # Ask AI for coordination decision
        prompt = f"""
        Robot fleet status:
        {self.robot_states}

        Suggest optimal task allocation for package delivery.
        """

        self.ai_pub.publish(String(data=prompt))

def main():
    rclpy.init()
    node = FleetCoordinatorNode()
    rclpy.spin(node)
    rclpy.shutdown()

if __name__ == '__main__':
    main()
```

---

## Performance

### Latency Benchmarks

| Scenario | ROS2 Overhead | Inference Time | Total Latency |
|----------|---------------|----------------|---------------|
| Simple text query | ~5ms | 245ms | **250ms** |
| Image analysis | ~15ms | 380ms | **395ms** |
| Multi-robot coordination | ~8ms | 210ms | **218ms** |

**ROS2 overhead:** Less than 10ms for most messages (DDS is very efficient)

### Throughput

- **Peak requests/sec:** 150 (limited by model inference, not ROS2)
- **Max concurrent subscribers:** 1000+ (DDS scales well)
- **Message size limit:** 100 MB (configurable via DDS)

---

## Message Type Definitions

### Custom Message: InferenceRequest

```
# igris_msgs/InferenceRequest.msg
string prompt
string model
int32 max_tokens
float32 temperature
string[] stop_sequences
bool stream
```

### Custom Message: InferenceResponse

```
# igris_msgs/InferenceResponse.msg
bool success
string response
int32 latency_ms
int32 tokens_used
string model_used
string error_message
```

### Custom Message: RuntimeStatus

```
# igris_msgs/RuntimeStatus.msg
string node_name
string status  # healthy, degraded, error
int64 uptime_secs
int32 active_requests
int64 total_requests
int32 error_count
bool model_loaded
string model_name
bool gpu_enabled
```

**To build custom messages:**
```bash
# Create ROS2 package
ros2 pkg create --build-type ament_cmake igris_msgs

# Add .msg files to msg/
# Build
colcon build --packages-select igris_msgs
```

---

## Troubleshooting

### ROS2 node not discovered

**Check domain ID:**
```bash
# Runtime and robot must be on same domain
echo $ROS_DOMAIN_ID  # Should match config.json5

# List all nodes on network
ros2 node list
```

**Check DDS discovery:**
```bash
# Enable verbose logging
export RMW_CONNEXT_VERBOSITY=3  # For Connext
export FASTRTPS_DEFAULT_PROFILES_FILE=fastdds_debug.xml  # For FastDDS

# Check multicast
ros2 multicast receive
ros2 multicast send
```

### Messages not received

**Check topic names:**
```bash
# List all topics
ros2 topic list

# Should show /igris/inference/request, /igris/inference/response, etc.
```

**Check message types:**
```bash
# Verify topic type
ros2 topic info /igris/inference/request

# Should show: std_msgs/msg/String (or custom type)
```

**Check QoS compatibility:**
```bash
# QoS must match between publisher and subscriber
ros2 topic info /igris/inference/request --verbose

# Compare QoS settings (reliability, durability, history)
```

### High latency

**Reduce QoS depth:**
```json5
{
  "ros2": {
    "depth": 1  // Reduce from 10 to minimize queuing delay
  }
}
```

**Use best_effort reliability:**
```json5
{
  "ros2": {
    "reliability": "best_effort"  // Faster but may drop messages
  }
}
```

**Increase executor threads:**
```json5
{
  "ros2": {
    "executor_threads": 8  // More threads for parallel processing
  }
}
```

---

## Best Practices

1. **Use appropriate QoS** - `sensor_data` for high-frequency sensors, `default` for commands
2. **Namespace your topics** - Use `/igris/*` to avoid conflicts
3. **Handle failures gracefully** - ROS2 network can be unreliable
4. **Monitor latency** - Subscribe to `/igris/metrics` for performance tracking
5. **Use services for sync** - Topics for async, services for request/reply
6. **Test with `ros2 topic echo`** - Always verify topics before integration
7. **Check DDS security** - Enable DDS security for production robots

---

## Security

### DDS Security (SROS2)

**Enable ROS2 security:**
```bash
# Generate security keys
ros2 security create_keystore ~/sros2_keystore
ros2 security create_key ~/sros2_keystore /igris/ai_inference_node

# Set environment variable
export ROS_SECURITY_KEYSTORE=~/sros2_keystore
export ROS_SECURITY_ENABLE=true
export ROS_SECURITY_STRATEGY=Enforce
```

**Update config:**
```json5
{
  "ros2": {
    "security": {
      "enabled": true,
      "keystore_path": "~/sros2_keystore",
      "strategy": "Enforce"  // Enforce or Permissive
    }
  }
}
```

### Access Control

**Restrict topics:**
```xml
<!-- permissions.xml -->
<permissions>
  <grant name="IgrisPermissions">
    <subject_name>/igris/ai_inference_node</subject_name>
    <allow_rule>
      <domains>
        <id>0</id>
      </domains>
      <publish>
        <topics>
          <topic>/igris/inference/response</topic>
          <topic>/igris/status</topic>
        </topics>
      </publish>
      <subscribe>
        <topics>
          <topic>/igris/inference/request</topic>
          <topic>/robot/camera/image</topic>
        </topics>
      </subscribe>
    </allow_rule>
  </grant>
</permissions>
```

---

## Roadmap

### Q1 2026
- [ ] Full multi-modal support (image + text prompts)
- [ ] Action server integration (for long-running tasks)
- [ ] Parameter server integration (dynamic config)
- [ ] Lifecycle node management

### Q2 2026
- [ ] ROS2 bag file playback for testing
- [ ] RViz plugin for visualization
- [ ] Behavior tree integration
- [ ] Nav2 plugin for AI-guided navigation

---

## Related Documentation

- [Multi-Modal Processing](/docs/multimodal) - Image and audio analysis
- [Configuration Reference](/docs/configuration) - Full config options
- [Performance Tuning](/docs/performance) - Optimization guide
- [ROS2 Integration Report](/PHASE3_ROS2_IMPLEMENTATION.md) - Implementation details

---

**Questions?** Join the discussion at [ROS Discourse - Igris Runtime](https://discourse.ros.org)
