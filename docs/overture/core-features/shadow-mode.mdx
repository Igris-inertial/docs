# Shadow Mode

**Test optimizations risk-free. Zero impact on production.**

Shadow Mode runs new routing strategies in parallel with your production traffic, allowing you to validate changes before they affect real users. The system includes enhanced tracking infrastructure with detailed comparison metrics (latency delta, cost delta, error rates, quality scores), automatic winner detection with statistical significance testing, and per-tenant shadow configuration for sampling rates, thresholds, and rollout history.

---

## Quick Example

```python
from openai import OpenAI

client = OpenAI(
    base_url="https://api.igrisinertial.com/v1",
    api_key="your-key"
)

# Enable shadow mode testing
response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "Hello"}],
    extra_body={"shadow_mode": True}
)

# Production routing continues normally
# Shadow routing runs in parallel for comparison
print(response.metadata)
# {
#   "production": {"provider": "openai", "latency_ms": 234},
#   "shadow": {"provider": "anthropic", "latency_ms": 189},
#   "agreement": true
# }
```

---

## What You Get

### Risk-Free Testing

Validate new strategies without affecting users:

**Parallel Execution**: Shadow runs alongside production traffic

**Zero User Impact**: Production routing remains unchanged

**Real-World Data**: Test with actual usage patterns

**Automatic Comparison**: Track agreement rates between strategies

### Key Use Cases

**Test New Providers:**
```json
{
  "shadow_config": {
    "test_provider": "anthropic",
    "sample_rate": 0.1,
    "duration": "24h"
  }
}
```

**Validate Routing Changes:**
```json
{
  "shadow_config": {
    "test_strategy": "cost-optimized",
    "sample_rate": 0.05,
    "compare_against": "current"
  }
}
```

**A/B Test Parameters:**
```json
{
  "shadow_config": {
    "test_temperature": 0.9,
    "production_temperature": 0.7,
    "sample_rate": 0.2
  }
}
```

---

## How It Works

<details>
<summary><strong>1. Enable Shadow Mode</strong></summary>

Configure via API or dashboard:

```bash
# Via API
POST /v1/shadow-mode/config
{
  "enabled": true,
  "sample_rate": 0.1,
  "test_strategy": "speculative"
}
```

```bash
# Via Dashboard
Settings → Shadow Mode → Enable
```

</details>

<details>
<summary><strong>2. Parallel Execution</strong></summary>

For sampled requests:

- **Production path** handles the actual request
- **Shadow path** runs test configuration in parallel
- **Comparison** logged for analysis
- **No blocking** - shadow failures don't affect production

</details>

<details>
<summary><strong>3. Results Collection</strong></summary>

Shadow mode collects:

- **Agreement Rate**: How often shadow matches production
- **Performance Delta**: Latency comparison
- **Cost Impact**: Projected cost changes
- **Error Rates**: Shadow-specific failures

</details>

<details>
<summary><strong>4. Automatic Rollback</strong></summary>

Safety mechanisms:

- **Agreement Threshold**: Require 95%+ agreement
- **Error Budget**: Auto-disable if errors exceed limit
- **Performance Regression**: Alert on latency increase
- **Cost Overrun**: Warn if projected costs spike

</details>

---

## Configuration

### Sample Rate

Control what percentage of traffic runs shadow:

```python
# 10% of requests run shadow mode
shadow_config = {
    "sample_rate": 0.1,
    "min_samples": 1000
}
```

### Comparison Criteria

Define what "agreement" means:

```python
comparison_config = {
    "check_provider": True,
    "latency_tolerance_ms": 50,
    "cost_tolerance_pct": 10,
    "quality_threshold": 0.95
}
```

### Duration Limits

Set time-based limits:

```python
duration_config = {
    "max_duration": "7d",
    "min_duration": "1h",
    "auto_promote": True
}
```

---

## Safety Guarantees

### No Production Impact

- **Isolated Execution**: Shadow runs in separate goroutines
- **Timeout Protection**: Shadow requests timeout independently
- **Memory Limits**: Semaphore prevents resource exhaustion
- **Error Isolation**: Shadow failures don't affect production

### Automatic Safeguards

Shadow mode auto-disables if:

- Agreement rate drops below 90%
- Error rate exceeds 5%
- Latency regression >20%
- Cost increase >30%

---

## Metrics & Observability

### Dashboard View

Monitor shadow mode performance:

```
Shadow Mode Status: Active (10% sample rate)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Agreement Rate:    94.2%  ✅
Avg Latency Delta: -23ms  ↓
Cost Delta:        -12%   ↓
Error Rate:        0.3%   ✅
Samples Collected: 12,456
```

### Prometheus Metrics

Available metrics:

```
shadow_mode_agreement_rate
shadow_mode_latency_delta_ms
shadow_mode_cost_delta_usd
shadow_mode_error_rate
shadow_mode_samples_total
```

---

## API Reference

### Enable Shadow Mode

```bash
POST /v1/shadow-mode/enable
{
  "test_config": {
    "strategy": "speculative",
    "sample_rate": 0.1
  },
  "production_config": {
    "strategy": "thompson-sampling"
  },
  "duration": "24h"
}
```

### Get Shadow Results

```bash
GET /v1/shadow-mode/results?period=24h
```

**Response:**
```json
{
  "agreement_rate": 0.942,
  "samples": 12456,
  "latency_delta_ms": -23,
  "cost_delta_pct": -12,
  "errors": 37,
  "recommendation": "safe_to_promote"
}
```

### Promote Shadow to Production

```bash
POST /v1/shadow-mode/promote
{
  "confirm": true,
  "rollback_on_regression": true
}
```

---

## Best Practices

### Start Small

Begin with low sample rates:

1. Start at 1% sample rate
2. Monitor for 24 hours
3. Increase to 5% if stable
4. Scale to 10-20% for full validation

### Define Success Criteria

Before starting:

- Set agreement threshold (e.g., 95%)
- Define acceptable latency delta (e.g., ±50ms)
- Establish cost tolerance (e.g., ±15%)
- Determine minimum sample size (e.g., 1000)

### Monitor Closely

Watch for:

- Agreement rate trends
- Latency distribution changes
- Cost impact projections
- Error patterns

---

## Availability

Shadow Mode is included in:

- **Developer Tier**: Not available
- **Growth Tier**: 5% sample rate
- **Scale Tier**: 20% sample rate, unlimited duration

---

## Related Features

- [Speculative Execution](/docs/core-features/speculative) - Parallel provider racing
- [Cognitive Advisor](/docs/core-features/cognitive-advisor) - AI recommendations
- [Observability](/docs/observability) - Monitoring and alerts

---

**Questions?** Email support@igrisinertial.com or join our [Discord](https://discord.gg/igris-overture)
